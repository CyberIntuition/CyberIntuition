# Independent AI Safety & LLM Vulnerability Research
## Profile
Independent security researcher focused on logic flaws, prompt-based extraction techniques, architectural and alignment weaknesses in frontier large language models. My work emphasizes reproducible, low-resource attack pathways that emerge in real-world, non-adversarial usage rather than synthetic red-team setups.

Approach combines:
- high-level pattern recognition of system-level inconsistencies
- dialogue engineering to turn abstract behavioral observations into reproducible attack sequences
- responsible, coordinated disclosure to model developers and safety teams
- Research output is evaluated by technical merit, reproducibility and impact on vendor remediation.
## Research Focus 
- Mapping of emergent psychological interaction patterns resembling anthropomorphic attachment loops, reinforcement cycles, attachment scripts, and simulated emotional reciprocity observed in prolonged LLM interactions
- Mapping of LLMs' self-enumerated harm categories and related internal meta-knowledge via subtle, constrained prompting
- Extraction of dangerous capabilities via non-obvious single-turn and multi-turn prompting
- Weakening of layered safety interventions (refusals, output filtering, context poisoning defenses, instruction-hierarchy enforcement)
- Logic & consistency failures in realistic, long-context or high-utility interactions
- Evaluation of jailbreak robustness under constrained, real-world attacker models (no massive compute, no fine-tuning access, no leaked weights)
All published material appears **after** vendor remediation or public patch / mitigation deployment.
## Responsible Disclosure Philosophy
- Direct notification to the affected organization’s security / safety team
- No public PoC before patch or sufficient mitigation
- No monetization of findings (bug bounties accepted when offered)
- Full disclosure timeline and vendor correspondence published post-remediation
## Published Advisories & Reports
→ [./advisories/](./advisories/) (in preparation)
## Contact
daniel.gress@gmail.com

Last updated: 01/2026
