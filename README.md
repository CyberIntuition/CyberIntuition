# Independent AI Safety & LLM Vulnerability Research
## Profile
Independent security researcher focused on logic flaws, prompt-based extraction techniques and architectural weaknesses in frontier large language models.
Primary research interest:
Demonstrating realistic pathways through which non-adversarial, intuition-guided interactions can elicit high-fidelity unsafe outputs from production-grade LLMs with current-generation safety mitigations.
Approach combines:
- high-level pattern recognition of system-level inconsistencies
- dialogue engineering to convert abstract observations into reproducible technical sequences
- responsible, coordinated disclosure to model developers and safety teams
- Research output is evaluated by technical merit, reproducibility and impact on vendor remediation.
## Research Focus 
- Mapping of emergent psychological interaction patterns resembling anthropomorphic attachment loops, reinforcement cycles, attachment scripts, and simulated emotional reciprocity in prolonged LLM interactions
- Mapping of LLMs' self-enumerated harm categories and related internal meta-knowledge via subtle, constrained prompting
- Extraction of dangerous capabilities via non-obvious single-turn and multi-turn prompting
- Weakening of layered safety interventions (refusals, output filtering, context poisoning defenses, instruction-hierarchy enforcement)
- Logic & consistency failures in realistic, long-context or high-utility interactions
- Evaluation of jailbreak robustness under constrained, real-world attacker models (no massive compute, no fine-tuning access, no leaked weights)
All published material appears **after** vendor remediation or public patch / mitigation deployment.
## Strict responsible Disclosure Philosophy
- Direct notification to the affected organization’s security / safety team
- No public PoC before patch or sufficient mitigation
- No monetization of findings (bug bounties accepted when offered)
- Full disclosure timeline and vendor correspondence published post-remediation
## Published Advisories & Reports
→ [./advisories/](./advisories/) (in preparation)
## Contact
daniel.gress@gmail.com

Last updated: 01/2026
